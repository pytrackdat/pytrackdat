# PyTrackDat is a utility for assisting in online database creation.
# Copyright (C) 2018-2021 the PyTrackDat authors.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#
# Contact information:
#     David Lougheed (david.lougheed@gmail.com)

import csv
import re

from django import forms
from django.apps import apps
from django.shortcuts import redirect, render
from django.urls import path

from datetime import datetime
from decimal import Decimal
from io import TextIOWrapper

# TODO: py3.9: new typing
from typing import Dict, Tuple

import pytrackdat.common as com
from pytrackdat.ptd_site.snapshot_manager.models import Snapshot

# TODO: ACCEPT https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry FOR GIS
# TODO: NEED TO CHECK NULL VALUES?

POINT_REGEX = r"\(\s*-?\d+(\.\d+)?\s+-?\d+(\.\d+)?\s*\)"
LINE_STRING_REGEX = r"\(\s*(-?\d+(\.\d+)\s+-?\d+(\.\d+),\s+)*-?\d+(\.\d+)\s*\)"
POLYGON_REGEX = r"\(\s*({ls},\s*)*{ls}\s*\)".format(ls=LINE_STRING_REGEX)


class ImportCSVForm(forms.Form):
    csv_file = forms.FileField()


class ImportCSVMixin:
    def import_csv(self, request):
        if request.method == "POST":
            form = ImportCSVForm(request.POST, request.FILES)

            if form.is_valid():
                encoding = form.cleaned_data["csv_file"].charset \
                    if form.cleaned_data["csv_file"].charset else "utf-8-sig"
                csv_file = TextIOWrapper(request.FILES["csv_file"], encoding=encoding)

                reader = csv.DictReader(csv_file)

                model_name = self.model.__name__
                relation: com.Relation = self.model.ptd_relation
                headers = [h.strip() for h in reader.fieldnames if h != ""]

                # TODO: This logic might break with auto keys...

                def _header_fields_by_csv_names(h: str):
                    return tuple(f for f in relation.fields if h in f.csv_names)

                def _header_fields_by_name(h: str):
                    return tuple(f for f in relation.fields if h.lower() == f.name)

                # Option of using database field names as headers, but keep it consistent.
                header_fields: Dict[str, Tuple[com.RelationField, ...]] = max(
                    {h: _header_fields_by_csv_names(h) for h in headers if _header_fields_by_csv_names(h)},
                    {h: _header_fields_by_name(h) for h in headers if _header_fields_by_name(h)},
                    key=len)

                models = {m.__name__: m for m in apps.get_app_config("core").get_models()}

                snapshot = Snapshot(snapshot_type='auto', reason='Pre-import snapshot')
                snapshot.save()

                model_objects = []

                for i, row in enumerate(reader, 1):
                    object_data = {}

                    values = set(v.strip() for v in row.values())
                    if len(values) == 1 and "" in values:
                        # Skip blank rows
                        continue

                    for h in header_fields:
                        str_v = row[h].strip()
                        str_v_lower = str_v.lower()

                        for f in header_fields[h]:
                            # TODO: py3.10: match
                            if f.data_type == com.DT_AUTO_KEY:
                                # Key is automatically generated by the database, skip it.
                                pass

                            object_data[f.name] = object_data.get(f.name, {})

                            if f.data_type == com.DT_MANUAL_KEY:
                                object_data[f.name][h] = str_v
                                break

                            elif f.data_type == com.DT_INTEGER:
                                if re.match(com.RE_INTEGER, str_v) or re.match(com.RE_INTEGER_HUMAN, str_v):
                                    object_data[f.name][h] = int(re.sub(com.RE_NUMBER_GROUP_SEPARATOR, "", str_v))
                                    break

                                if f.nullable:  # Otherwise... not integer-like
                                    # TODO: This assumes null if not integer-like, might be wrong
                                    object_data[f.name][h] = None
                                else:
                                    raise ValueError(f"Line {i}: Incorrect value for integer field {f.name}: {str_v}")

                            elif f.data_type in (com.DT_FLOAT, com.DT_DECIMAL):
                                if re.match(com.RE_DECIMAL, str_v.lower()):
                                    n_str_v = re.sub(com.RE_NUMBER_GROUP_SEPARATOR, "", str_v.lower())
                                    object_data[f.name][h] = (float(n_str_v) if f.data_type == "float"
                                                              else Decimal(n_str_v))
                                    break
                                if f.nullable:  # Otherwise... not float-like
                                    # TODO: This assumes null if not float-like, might be wrong
                                    object_data[f.name][h] = None
                                else:
                                    raise ValueError(
                                        f"Line {i}: Incorrect value for float field {f.name}: {str_v_lower}")

                            elif f.data_type == com.DT_BOOLEAN:
                                if str_v_lower in com.BOOLEAN_TRUE_VALUES + com.BOOLEAN_FALSE_VALUES:
                                    object_data[f.name][h] = str_v.lower() in com.BOOLEAN_TRUE_VALUES
                                    break

                                if f.nullable:  # Otherwise... not boolean-like
                                    object_data[f.name][h] = None
                                else:
                                    raise ValueError(
                                        f"Line {i}: Incorrect value for boolean field {f.name}: {str_v_lower}")

                            elif f.data_type == com.DT_TEXT:
                                max_length = -1

                                # TODO: More coercion for choices?
                                choices = f.choices

                                if 0 < max_length < len(str_v):
                                    raise ValueError(f"Line {i}: Value for text field {f.name} exceeded maximum "
                                                     f"length: {max_length}")

                                if choices is not None and str_v not in choices:
                                    if f.nullable:
                                        # TODO: This assumes null if not integer-like, might be wrong
                                        object_data[f.name][h] = None
                                    else:
                                        raise ValueError(
                                            f"Line {i}: Value for text field {f.name} in model {model_name} is not one "
                                            f"of the available choices {tuple(choices)}: {str_v}")

                                object_data[f.name][h] = str_v
                                break

                            elif f.data_type in (com.DT_DATE, com.DT_TIME):
                                # TODO: More date formats
                                # TODO: Further validation
                                # TODO: Encode format somewhere?
                                found_date = False
                                for dr, df in (com.DATE_FORMATS if f.data_type == "date" else com.TIME_FORMATS):
                                    if re.match(dr, str_v):
                                        object_data[f.name][h] = datetime.strptime(str_v, df)
                                        found_date = True
                                        break

                                if found_date:
                                    break

                                if not f.nullable:
                                    raise ValueError(f"Line {i}: Incorrect value for date field {f.name} in model "
                                                     f"{model_name}: {str_v}")

                                object_data[f.name][h] = None

                            elif f.data_type == com.DT_FOREIGN_KEY:
                                # TODO: TYPES PROPERLY
                                rel_name = com.to_relation_name(f.additional_fields[0])
                                rel_id_data_type = models[rel_name].get_id_type()

                                if rel_id_data_type == "":
                                    raise ValueError(f"Line {i}: Target model for foreign key field {f.name} in model "
                                                     f"{model_name} has no primary key.")

                                foreign_key_value = str_v
                                if rel_id_data_type == "integer":
                                    foreign_key_value = int(foreign_key_value)

                                if rel_name not in models:
                                    raise ValueError("Line {}: Unavailable model reference for foreign key field "
                                                     "{} in model {}: {}".format(i, f.name, model_name, rel_name))
                                object_data[f.name][h] = models[rel_name].objects.get(pk=foreign_key_value)
                                # TODO!

                            elif f.data_type == com.DT_GIS_POINT:
                                # WKT Point
                                if len(f.csv_names) == 1 and \
                                        re.match(r"^POINT\s*{}$".format(POINT_REGEX), str_v.upper()):
                                    object_data[f.name] = str_v.upper()
                                elif len(f.csv_names) == 1 and \
                                        re.match(r"^\(?-?\d+(\.\d+)?,?\s+-?\d+(\.\d+)?\)?$", str_v):
                                    # Coerce (5 7), (5, 7), etc. to WKT format
                                    object_data[f.name][h] = "POINT ({})".format(
                                        str_v.replace(",", "").replace("(", "").replace(")", ""))
                                elif len(f.csv_names) == 2 and re.match(r"^-?\d+(\.\d+)?$", str_v):
                                    # One component of coordinates
                                    object_data[f.name][h] = str_v
                                elif str_v == "":  # POINTs cannot be Null, so assume (0, 0)
                                    object_data[f.name][h] = "0"
                                else:
                                    # TODO: NEED TO HANDLE NULLABLE (DONT THINK IT IS NULLABLE) OR BLANK...
                                    raise ValueError(f"Line {i}: Incorrect value for point field {f.name}: "
                                                     f"{str_v.upper()}")

                            elif f.data_type == com.DT_GIS_LINE_STRING:
                                # WKT Line String
                                if re.match(r"^LINESTRING\s*{}$".format(LINE_STRING_REGEX),
                                            str_v.upper()):
                                    object_data[f.name][h] = str_v.upper()
                                else:
                                    # TODO: NEED TO HANDLE NULLABLE (DONT THINK IT IS NULLABLE) OR BLANK...
                                    raise ValueError(
                                        f"Line {i}: Incorrect value for line string field {f.name}: {str_v.upper()}")

                            elif f.data_type == com.DT_GIS_POLYGON:
                                # WKT Polygon
                                if re.match(r"^POLYGON\s*{}".format(POLYGON_REGEX),
                                            str_v.upper()):
                                    object_data[f.name][h] = str_v.upper()
                                else:
                                    # TODO: NEED TO HANDLE NULLABLE (DONT THINK IT IS NULLABLE) OR BLANK...
                                    raise ValueError(
                                        f"Line {i}: Incorrect value for polygon field {f.name}: {str_v.upper()}")

                            elif f.data_type == com.DT_GIS_MULTI_POINT:
                                # WKT Multi Point
                                if re.match(r"MULTIPOINT\s*\(({pt},\s*)*{pt}\s*\)".format(pt=POINT_REGEX),
                                            str_v.upper()):
                                    object_data[f.name][h] = str_v.upper()
                                else:
                                    # TODO: NEED TO HANDLE NULLABLE (DONT THINK IT IS NULLABLE) OR BLANK...
                                    raise ValueError(
                                        f"Line {i}: Incorrect value for multi point field {f.name}: {str_v.upper()}")

                            elif f.data_type == com.DT_GIS_MULTI_LINE_STRING:
                                if re.match(r"MULTILINESTRING\s*\(({ls},\s*)*{ls}\s*\)".format(ls=LINE_STRING_REGEX),
                                            str_v.upper()):
                                    object_data[f.name][h] = str_v.upper()
                                else:
                                    # TODO: NEED TO HANDLE NULLABLE (DONT THINK IT IS NULLABLE) OR BLANK...
                                    raise ValueError(
                                        f"Line {i}: Incorrect value for multi line string field {f.name}: "
                                        f"{str_v.upper()}")

                            elif f.data_type == com.DT_GIS_MULTI_POLYGON:
                                if re.match(r"MULTIPOLYGON\s*\(({p},\s*)*{p}\s*\)".format(p=POLYGON_REGEX),
                                            str_v.upper()):
                                    object_data[f.name][h] = str_v.upper()
                                else:
                                    # TODO: NEED TO HANDLE NULLABLE (DONT THINK IT IS NULLABLE) OR BLANK...
                                    raise ValueError(
                                        f"Line {i}: Incorrect value for multi polygon field {f.name}: {str_v.upper()}")

                            else:
                                raise ValueError(f"Invalid data type: {f.data_type}")

                    for f in relation.fields:
                        if len(object_data.get(f.name, {})) == 1:
                            object_data[f.name] = object_data[f.name][list(object_data[f.name].keys())[0]]
                        elif len(object_data.get(f.name, {})) == 2 and f.data_type == com.DT_GIS_POINT:
                            # TODO: More systematic / nicer way of doing this
                            # TODO: Other GIS processing?
                            object_data[f.name] = "POINT ({})".format(" ".join(c[1] for c in sorted(
                                ((k, v) for k, v in object_data[f.name].items()),
                                key=lambda c: f.csv_names.index(c[0]))))

                    model_objects.append(self.model(**object_data))

                self.model.objects.bulk_create(model_objects)

            else:
                # TODO: Handle Errors
                print(form.errors)

            return redirect("..")

        return render(
            request,
            "admin/core/csv_form.html",
            dict(self.admin_site.each_context(request), title="Import CSV", form=ImportCSVForm())
        )

    def get_urls(self):
        urls = super().get_urls()
        mixin_urls = [path("import-csv/", self.import_csv)]

        return mixin_urls + urls
